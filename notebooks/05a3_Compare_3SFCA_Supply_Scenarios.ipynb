{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aa0295fd-55c3-4bc6-a925-09c94427998d",
   "metadata": {},
   "source": [
    "# 05a3 – Compare 3SFCA Accessibility Across CT Supply Scenarios\n",
    "\n",
    "This notebook visualises and compares spatial accessibility to CT scanners under four different supply scenarios using the Enhanced 3-Step Floating Catchment Area (E3SFCA) method.\n",
    "\n",
    "## Objectives\n",
    "- Compute E3SFCA accessibility scores under:\n",
    "  - Baseline (existing 36 CT sites)\n",
    "  - +5% uplift (4 new sites)\n",
    "  - +10% uplift (6 new sites)\n",
    "  - +20% uplift (8 new sites)\n",
    "- Use consistent travel time matrix and decay weighting\n",
    "- Produce 4 side-by-side maps for comparison\n",
    "- Interpret differences in access coverage and equity impact\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ccaa9fbc-3bec-45e0-b25b-4e959475882b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------------------------------\n",
    "# Step 0 – Imports and Display Setup\n",
    "# ----------------------------------------------------------\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import contextily as c\n",
    "import seaborn as sns\n",
    "import mapclassify\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aab64ce4-1bd2-4c81-b5bc-f44463a8a594",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------------------------------\n",
    "# Step 1 – Define File Paths and Load Baseline Inputs\n",
    "# ----------------------------------------------------------\n",
    "\n",
    "# Base directory structure\n",
    "base_dir = \"/Users/rosstaylor/Downloads/Research Project/Code Folder/diagnostic-modality-demand/diagnostic-modality-demand\"\n",
    "data_dir = os.path.join(base_dir, \"data\")\n",
    "processed_dir = os.path.join(data_dir, \"processed\")\n",
    "e3sfca_dir = os.path.join(processed_dir, \"E3SFCA\")\n",
    "raw_dir = os.path.join(data_dir, \"raw\")\n",
    "\n",
    "# Input files \n",
    "lsoa_access_path = os.path.join(e3sfca_dir, \"lsoa_e3sfca_accessibility_2024.gpkg\")\n",
    "travel_matrix_path = os.path.join(e3sfca_dir, \"lsoa_to_ct_travel_matrix_car.csv\")\n",
    "\n",
    "ct_sites_baseline_path = os.path.join(processed_dir, \"ct_sites_capability_baseline.csv\")\n",
    "ct_sites_5pct_path = os.path.join(processed_dir, \"ct_sites_capability_plus5pct.csv\")\n",
    "ct_sites_10pct_path = os.path.join(processed_dir, \"ct_sites_capability_plus10pct.csv\")\n",
    "ct_sites_20pct_path = os.path.join(processed_dir, \"ct_sites_capability_plus20pct.csv\")\n",
    "\n",
    "# Load base inputs\n",
    "gdf_lsoa = gpd.read_file(lsoa_access_path)\n",
    "df_travel = pd.read_csv(travel_matrix_path)\n",
    "\n",
    "print(\"LSOA accessibility GeoDataFrame:\", gdf_lsoa.shape)\n",
    "print(\"Travel matrix (car mode):\", df_travel.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f5ce3cb3-7b2d-473c-b6ee-8be9223c2bbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "baseline: 36 sites loaded\n",
      "+5%: 4 sites loaded\n",
      "+10%: 6 sites loaded\n",
      "+20%: 8 sites loaded\n"
     ]
    }
   ],
   "source": [
    "# ----------------------------------------------------------\n",
    "# Step 2 – Load CT Supply Scenarios\n",
    "# ----------------------------------------------------------\n",
    "\n",
    "# Define supply file paths\n",
    "supply_paths = {\n",
    "    \"baseline\": ct_sites_baseline_path,\n",
    "    \"+5%\": ct_sites_5pct_path,\n",
    "    \"+10%\": ct_sites_10pct_path,\n",
    "    \"+20%\": ct_sites_20pct_path\n",
    "}\n",
    "\n",
    "# Load each CSV into a GeoDataFrame with lat/lon geometry\n",
    "supply_scenarios = {}\n",
    "for label, path in supply_paths.items():\n",
    "    df = pd.read_csv(path)\n",
    "    gdf = gpd.GeoDataFrame(\n",
    "        df,\n",
    "        geometry=gpd.points_from_xy(df[\"longitude\"], df[\"latitude\"]),\n",
    "        crs=\"EPSG:4326\"\n",
    "    )\n",
    "    supply_scenarios[label] = gdf\n",
    "    print(f\"{label}: {gdf.shape[0]} sites loaded\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2f13997f-dbcf-4256-b9d3-8b10d1c11953",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- BASELINE SCENARIO ---\n",
      "Columns: ['site_name', 'scanner_count', 'site_type', 'latitude', 'longitude', 'destination_name', 'geometry']\n",
      "First 3 rows:\n",
      "                        site_name  scanner_count site_type   latitude  \\\n",
      "0     Cheltenham General Hospital              2     Acute  51.892120   \n",
      "1  Gloucestershire Royal Hospital              4     Acute  51.866379   \n",
      "2          Musgrove Park Hospital              3     Acute  51.011574   \n",
      "\n",
      "   longitude destination_name                   geometry  \n",
      "0  -2.071883        E01022116  POINT (-2.07188 51.89212)  \n",
      "1  -2.232073        E01022312  POINT (-2.23207 51.86638)  \n",
      "2  -3.121693        E01029302  POINT (-3.12169 51.01157)  \n",
      "\n",
      "----------------------------------------\n",
      "\n",
      "--- +5% SCENARIO ---\n",
      "Columns: ['site_name', 'scanner_count', 'site_type', 'latitude', 'longitude', 'geometry', 'destination_name']\n",
      "First 3 rows:\n",
      "         site_name  scanner_count     site_type   latitude  longitude  \\\n",
      "0  Scenario Site 1              1  Scenario +5%  50.306324  -5.006112   \n",
      "1  Scenario Site 2              1  Scenario +5%  51.123190  -2.330967   \n",
      "2  Scenario Site 3              1  Scenario +5%  50.731251  -3.851284   \n",
      "\n",
      "                    geometry destination_name  \n",
      "0  POINT (-5.00611 50.30632)        E01018815  \n",
      "1  POINT (-2.33097 51.12319)        E01032036  \n",
      "2  POINT (-3.85128 50.73125)        E01020319  \n",
      "\n",
      "----------------------------------------\n",
      "\n",
      "--- +10% SCENARIO ---\n",
      "Columns: ['site_name', 'scanner_count', 'site_type', 'latitude', 'longitude', 'geometry', 'destination_name']\n",
      "First 3 rows:\n",
      "         site_name  scanner_count      site_type   latitude  longitude  \\\n",
      "0  Scenario Site 1              2  Scenario +10%  50.284460  -5.059612   \n",
      "1  Scenario Site 2              2  Scenario +10%  50.614927  -4.101582   \n",
      "2  Scenario Site 3              1  Scenario +10%  51.325652  -2.120465   \n",
      "\n",
      "                    geometry destination_name  \n",
      "0  POINT (-5.05961 50.28446)        E01018821  \n",
      "1  POINT (-4.10158 50.61493)        E01020324  \n",
      "2  POINT (-2.12046 51.32565)        E01034540  \n",
      "\n",
      "----------------------------------------\n",
      "\n",
      "--- +20% SCENARIO ---\n",
      "Columns: ['site_name', 'scanner_count', 'site_type', 'latitude', 'longitude', 'geometry', 'destination_name']\n",
      "First 3 rows:\n",
      "         site_name  scanner_count      site_type   latitude  longitude  \\\n",
      "0  Scenario Site 1              2  Scenario +20%  50.270349  -5.085244   \n",
      "1  Scenario Site 2              2  Scenario +20%  51.324339  -2.063824   \n",
      "2  Scenario Site 3              2  Scenario +20%  50.637231  -4.366601   \n",
      "\n",
      "                    geometry destination_name  \n",
      "0  POINT (-5.08524 50.27035)        E01034862  \n",
      "1  POINT (-2.06382 51.32434)        E01031848  \n",
      "2   POINT (-4.3666 50.63723)        E01018948  \n",
      "\n",
      "----------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for label, gdf in supply_scenarios.items():\n",
    "    print(f\"--- {label.upper()} SCENARIO ---\")\n",
    "    print(\"Columns:\", gdf.columns.tolist())\n",
    "    print(\"First 3 rows:\")\n",
    "    print(gdf.head(3))\n",
    "    print(\"\\n\" + \"-\"*40 + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b2dfd6aa-2de4-4280-9fc9-7773a2449ede",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+5% scenario sample coords → {'site_name': 'Scenario Site 1', 'latitude': 49.767253800032464, 'longitude': -7.557330219609399}\n",
      "+10% scenario sample coords → {'site_name': 'Scenario Site 1', 'latitude': 49.76725356877222, 'longitude': -7.557330931673617}\n",
      "+20% scenario sample coords → {'site_name': 'Scenario Site 1', 'latitude': 49.76725342542688, 'longitude': -7.557331268908025}\n"
     ]
    }
   ],
   "source": [
    "# ----------------------------------------------------------\n",
    "# Step 3 – Assign Correct CRS (BNG) to Scenarios, Reproject to WGS84 & Recompute Lat/Lon\n",
    "# ----------------------------------------------------------\n",
    "for label in [\"+5%\", \"+10%\", \"+20%\"]:\n",
    "    # 1. Grab the scenario GeoDataFrame\n",
    "    gdf = supply_scenarios[label].copy()\n",
    "    \n",
    "    # 2. It’s actually in British National Grid but un‐labelled: force EPSG:27700\n",
    "    gdf = gpd.GeoDataFrame(gdf, geometry=\"geometry\", crs=\"EPSG:27700\", copy=True)\n",
    "    \n",
    "    # 3. Now reproject to WGS84\n",
    "    gdf = gdf.to_crs(epsg=4326)\n",
    "    \n",
    "    # 4. Recompute human-readable lat/lon\n",
    "    gdf[\"latitude\"]  = gdf.geometry.y\n",
    "    gdf[\"longitude\"] = gdf.geometry.x\n",
    "    \n",
    "    # 5. Overwrite back\n",
    "    supply_scenarios[label] = gdf\n",
    "    \n",
    "    # 6. Quick sanity check\n",
    "    rec = gdf[[\"site_name\",\"latitude\",\"longitude\"]].iloc[0].to_dict()\n",
    "    print(f\"{label} scenario sample coords → {rec}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "208383c1-2ba7-4b56-831e-332250f84e30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exported combined baseline + +5% → /Users/rosstaylor/Downloads/Research Project/Code Folder/diagnostic-modality-demand/diagnostic-modality-demand/data/processed/ct_sites_capability_plus5pct_all.csv\n",
      "Exported combined baseline + +10% → /Users/rosstaylor/Downloads/Research Project/Code Folder/diagnostic-modality-demand/diagnostic-modality-demand/data/processed/ct_sites_capability_plus10pct_all.csv\n",
      "Exported combined baseline + +20% → /Users/rosstaylor/Downloads/Research Project/Code Folder/diagnostic-modality-demand/diagnostic-modality-demand/data/processed/ct_sites_capability_plus20pct_all.csv\n"
     ]
    }
   ],
   "source": [
    "# ----------------------------------------------------------\n",
    "# Step 4 – Merge Baseline + Scenario Sites and Export Combined Lists\n",
    "# ----------------------------------------------------------\n",
    "\n",
    "# Make sure your baseline is in the dict\n",
    "baseline_gdf = supply_scenarios[\"baseline\"]\n",
    "\n",
    "# Output folder\n",
    "output_dir = \"/Users/rosstaylor/Downloads/Research Project/Code Folder/diagnostic-modality-demand/diagnostic-modality-demand/data/processed\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "for label in [\"+5%\", \"+10%\", \"+20%\"]:\n",
    "    # grab the scenario sites\n",
    "    scenario_gdf = supply_scenarios[label]\n",
    "    \n",
    "    # concatenate baseline + scenario\n",
    "    combined = pd.concat([baseline_gdf, scenario_gdf], ignore_index=True)\n",
    "    \n",
    "    # select only the export columns\n",
    "    export_df = combined[[\n",
    "        \"site_name\", \"scanner_count\", \"site_type\",\n",
    "        \"latitude\", \"longitude\", \"destination_name\"\n",
    "    ]]\n",
    "    \n",
    "    # build a clean filename\n",
    "    fname = label.replace(\"+\", \"plus\").replace(\"%\", \"pct\").lower()\n",
    "    path = os.path.join(output_dir, f\"ct_sites_capability_{fname}_all.csv\")\n",
    "    \n",
    "    export_df.to_csv(path, index=False)\n",
    "    print(f\"Exported combined baseline + {label} → {path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "55bc6589-e1f5-481a-a1d3-9cd8d1e8987c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Baseline (ct_sites_capability_baseline.csv) ---\n",
      "Shape: (36, 6)\n",
      "Columns: ['site_name', 'scanner_count', 'site_type', 'latitude', 'longitude', 'destination_name']\n",
      "\n",
      "--- +5% All Sites (ct_sites_capability_plus5pct_all.csv) ---\n",
      "Shape: (40, 6)\n",
      "Columns: ['site_name', 'scanner_count', 'site_type', 'latitude', 'longitude', 'destination_name']\n",
      "\n",
      "--- +10% All Sites (ct_sites_capability_plus10pct_all.csv) ---\n",
      "Shape: (42, 6)\n",
      "Columns: ['site_name', 'scanner_count', 'site_type', 'latitude', 'longitude', 'destination_name']\n",
      "\n",
      "--- +20% All Sites (ct_sites_capability_plus20pct_all.csv) ---\n",
      "Shape: (44, 6)\n",
      "Columns: ['site_name', 'scanner_count', 'site_type', 'latitude', 'longitude', 'destination_name']\n"
     ]
    }
   ],
   "source": [
    "# ----------------------------------------------------------\n",
    "# Step 5 – Verify Exported CSVs (Shapes & Column Names)\n",
    "# ----------------------------------------------------------\n",
    "\n",
    "# Directory where you exported the CSVs\n",
    "output_dir = (\n",
    "    \"/Users/rosstaylor/Downloads/Research Project/Code Folder/\"\n",
    "    \"diagnostic-modality-demand/diagnostic-modality-demand/data/processed\"\n",
    ")\n",
    "\n",
    "# Files to check\n",
    "csv_files = {\n",
    "    \"Baseline\":           \"ct_sites_capability_baseline.csv\",\n",
    "    \"+5% All Sites\":      \"ct_sites_capability_plus5pct_all.csv\",\n",
    "    \"+10% All Sites\":     \"ct_sites_capability_plus10pct_all.csv\",\n",
    "    \"+20% All Sites\":     \"ct_sites_capability_plus20pct_all.csv\"\n",
    "}\n",
    "\n",
    "for label, fname in csv_files.items():\n",
    "    path = os.path.join(output_dir, fname)\n",
    "    df = pd.read_csv(path)\n",
    "    print(f\"\\n--- {label} ({fname}) ---\")\n",
    "    print(\"Shape:\", df.shape)\n",
    "    print(\"Columns:\", df.columns.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e76f0c22-2764-40e6-a735-9bec87dad827",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d47b94e-81a3-4ca2-857c-858b32822ef0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19a393df-67e7-48c8-b242-d7d61f77c908",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00b12ad7-c15c-4b7c-89c5-31d1d53d1c8c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48df3881-5a55-4758-bc75-a3c5deaa73ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a5462f3-dc68-4bbe-866b-a041d2973189",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48dc6a25-dd38-424d-b556-867256a38089",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "692b69dc-942a-4559-915a-a4a924b3ac27",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fc97a13-d1d4-45aa-b104-7d2d8900a0e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b765099d-b349-4a2f-b988-308364dd9e90",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "081e263d-a959-4959-896a-99925e169094",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56011668-11d8-4983-9093-0dfd07de51f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac8a041f-f938-4c68-ae27-939e803963cc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
